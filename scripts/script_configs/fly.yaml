Comment: >
  Run:
  python run.py --config-name="fly" trainer_cfg.fast_dev_run=1
  python run.py --config-name="fly" trainer_cfg.fast_dev_run=1 module_cfg.module="segmenterBsoft_module"
  python run.py --config-name="fly" trainer_cfg.max_epochs=10
project_name: "data_fly"
experiment_name: "run_fly_repro"

data_cfg:
  test_set: "concat_all"
  data_dir: ${oc.env:LOCAL_PROJECTS_DIR}/segment/action/data/fly
  expt_ids:
    - 2019_06_26_fly2
    - 2019_08_07_fly2
    #- 2019_08_08_fly1
    #- 2019_08_20_fly2
    #- 2019_10_21_fly1
  ood_expt_ids:
    - 2019_08_14_fly1
    #- 2019_10_14_fly3
    #- 2019_10_14_fly2
    #- 2019_08_20_fly3
    #- 2019_10_10_fly3
  input_type: "markers"
  input_size: 16
  sequence_length: 20
  num_classes: 7
  batch_size: 32
  num_workers: 32
  seed: null
  train_split : 0.8
  val_split: 0.1

#  sequence_pad: null # inherited from dataloader
# class_idx: null
#  encodings: null
#   samples_per_class: null

trainer_cfg:
  fast_dev_run: 0
  logger: "wandb"
  deterministic: false
  log_every_n_steps: 1
  max_epochs: 200
  precision: 32
  accelerator: "auto"
  val_check_interval: 1.0  # set to 1 for early stopping
  gradient_clip_val: 0
  gradient_clip_algorithm: "value" #"norm"

eval_cfg:
  eval_only: 0
  ckpt_path: null
  return_model: 0  # debugger to return model

callbacks:
  gradnorm: 0
  checkpoint_callback: 0
  early_stopping: 0
  lr_monitor: 0   #this one?

early_stop_cfg:
  monitor: "epoch/val_accuracy"
  mode: max
  verbose: true
  min_delta: 0.0
  patience: 20  # related to val_check_interval

module_cfg:
  module: "segmenter_module"
  lambda_strong: 1  # hyperparam on classifying strong (hand) labels
  lambda_weak: 0.5  # hyperparam on classifying weak (heuristic) labels
  lambda_pred: 0.5  # hyperparam on one-step-ahead prediction
  sequence_pad: 16
  #samples_per_class: null  # inherit from train_dataloader
  optimizer_cfg:
    lr: 1e-4
    amsgrad: True
  classifier: "segmenter" # name of classifier for experiment
  classifier_cfg:
    model_class: "multiclass"
    backbone : "dtcn"
    n_hid_layers: 2      # hidden layers in network
    n_hid_units: 32      # hidden units per hidden layer
    n_lags: 4            # half-width of temporal convolution window
    activation: 'lrelu'  # layer nonlinearity
    bidirectional: "true"
    dropout: 0.1
    classifier_type: "multiclass" # can also be binary
    variational: false

    #input_size: null       # inherit dimensionality of markers
    #num_classes: null  # inherit from train_dataloader

seed: 0

hydra:
  run:
    dir: ./outputs/${now:%y-%m-%d}/${now:%H-%M-%S}