Comment: >
  # Debugging instructions:
  python run.py --config-name="fly_daart" trainer_cfg.fast_dev_run=1 data_cfg.num_workers=4
  # match performance of example
  python run.py --config-name="fly_daart" eval_cfg.eval_only=1 eval_cfg.ckpt_path="/data/Projects/segment/daart/results/best_val_model.pt"

project_name: "data_fly"
experiment_name: "run_fly_repro"

# Common variables:
common:
  input_type: &input_type "markers"   # input signal
  sequence_length: &sequence_length 500 # length of sequence
  input_size: &input_size 16  # dimensionality of input type
  num_classes: &num_classes 7 # number of classes
  lambda_strong: &lambda_strong 1  # hyperparam on classifying strong (hand) labels
  lambda_weak: &lambda_weak 0.5   # hyperparam on classifying weak (heuristic) labels
  lambda_pred: &lambda_pred 0.5  # hyperparam on one-step-ahead prediction
  lambda_recon: &lambda_recon 0 # hyperparam on reconstruction loss
  lambda_task: &lambda_task 0 # hyperparam on task prediction loss


data_cfg:
  test_set: "base"
  data_dir: ${oc.env:LOCAL_PROJECTS_DIR}/segment/action/data/fly_daart
  expt_ids:
    - 2019_06_26_fly2
  ood_expt_ids:
    - 2019_06_26_fly2  # 2019_06_26_fly2 to reproduce example evaluated on all the data
  batch_size: 32
  num_workers: 32
  seed: null
  train_split : 0.8
  val_split: 0.1
  input_type: *input_type
  input_size: *input_size  # dimensionality of input type
  sequence_length: *sequence_length
  num_classes: *num_classes
  lambda_weak: *lambda_weak
  lambda_strong: *lambda_strong
  lambda_pred: *lambda_pred
  lambda_recon: *lambda_recon
  lambda_task: *lambda_task

trainer_cfg:
  fast_dev_run: 0
  logger: "wandb"
  deterministic: false
  log_every_n_steps: 1
  max_epochs: 200
  precision: 32
  accelerator: "auto"
  val_check_interval: 1.0  # set to 1 for early stopping
  gradient_clip_val: 0.5
  gradient_clip_algorithm: "value" #"norm"

eval_cfg:
  eval_only: 0   # run evaluation only pipeline
  ckpt_path: 
  return_model: 0  # debugger to return model

callbacks:
  gradnorm: 1
  checkpoint_callback: 0
  early_stopping: 0
  lr_monitor: 0   #this one?

early_stop_cfg:
  monitor: "epoch/val_accuracy"
  mode: max
  verbose: true
  min_delta: 0.0
  patience: 10  # related to val_check_interval

module_cfg:
  module: "segmenter_module"  # lightning module
  input_type: *input_type
  lambda_weak: *lambda_weak
  lambda_strong: *lambda_strong
  lambda_pred: *lambda_pred
  lambda_recon: *lambda_recon
  lambda_task: *lambda_task
  optimizer_cfg:
    type: "adam"
    lr: 1e-4
    amsgrad: True
  classifier: "encoder_decoder"  # model class
  classifier_cfg:
    model_class: "deep"
    backbone : "dtcn"
    n_hid_layers: 2      # hidden layers in network
    n_hid_units: 32      # hidden units per hidden layer
    n_lags: 4            # half-width of temporal convolution window
    activation: 'lrelu'  # layer nonlinearity
    bidirectional: "true"
    dropout: 0.1
    classifier_type: "multiclass" # [multiclass, multilabel]
    variational: false

seed: 0

fiftyone_cfg:
  dataset_name: "fly_daart"

hydra:
  run:
    dir: ./outputs/${now:%y-%m-%d}/${now:%H-%M-%S}
